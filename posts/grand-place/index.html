<!doctype html><html xmlns=http://www.w3.org/1999/xhtml lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Grand Place people and car detection | Jeroen Nyckees</title><link rel=stylesheet href=https://jenyckee.github.io/css/style.css><link rel=stylesheet href=/css/custom.css><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity="sha256-3edrmyuQ0w65f8gfBsqowzjJe2iM6n0nKciPUp8y+7E=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/d3/4.1.0/d3.js></script><script src=https://d3js.org/topojson.v2.min.js></script></head><body><section class=section><div class=container><nav class=nav><div class=nav-right></div></nav><div class=nav-center><nav class="nav-item level is-mobile"><div class=nav-left><a class=nav-item href=https://jenyckee.github.io/><img class=avatar src=/svg/avatar.svg alt=#></a></div><div><h1>Jeroen Nyckees</h1><div class=text-center><a class=level-item href=mailto:jeroen.nyckees@gmail.com target=_blank rel=noopener><span class=icon><i><svg viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M4 4h16c1.1.0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1.0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><polyline points="22,6 12,13 2,6"/></svg>
</i></span></a><a class=level-item href=https://github.com/jenyckee target=_blank rel=noopener><span class=icon><i><svg viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg>
</i></span></a><a class=level-item href=https://linkedin.com/in/jeroen-nyckees-3a191582/ target=_blank rel=noopener><span class=icon><i><svg viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path stroke-width="1.8" d="m5.839218 4.101561c0 1.211972-.974141 2.194011-2.176459 2.194011S1.4863 5.313533 1.4863 4.101561c0-1.211094.974141-2.194011 2.176459-2.194011s2.176459.982917 2.176459 2.194011zm.017552 3.94922H1.468748v14.04167H5.85677V8.050781zm7.005038.0H8.501869v14.04167h4.360816v-7.370999c0-4.098413 5.291077-4.433657 5.291077.0v7.370999h4.377491v-8.89101c0-6.915523-7.829986-6.66365-9.669445-3.259423V8.050781z"/></svg></i></span></a></div></div></nav></div></div></section><section class=section><div class=container><div class="subtitle tags is-6 is-pulled-right"><a class="subtitle is-6" href=/tags/computer-vision/>#computer vision</a>
| <a class="subtitle is-6" href=/tags/tensorflow/>#TensorFlow</a></div><h2 class="subtitle is-6">February 1, 2020</h2><h1 class=title>Grand Place people and car detection</h1><div class=content><p>On <a href=http://www.brussel.be/webcam-grote-markt>http://www.brussel.be/webcam-grote-markt</a> you can find a webcam stream of the Grand Place in Brussels. When I saw this I was wondering if I could build a model to trace individual people and eventually track their behaviour while walking on one of the most touristy spots in Brussels.</p><p>I set up a website with TensorFlow.js using the <a href=https://github.com/tensorflow/tfjs-models/tree/master/coco-ssd>coco-ssd</a> model but was slightly dissapointed with the results. After doing some more research I read about transfer learning and decided to try and improve model.</p><p>I recorded several short clips of the webcam stream using ffmpeg.<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>ffmpeg -i http://stream.brucity.be/BXLCAM/CAM-GrandePlace.stream/chunklist_w1781624015.m3u8 -c copy -bsf:a aac_adtstoasc output.mp4</span></span></code></pre></div>And eventually chopped the video into frames.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>ffmpeg -i <span style=color:#e6db74>&#34;output.mp4&#34;</span> <span style=color:#e6db74>&#34;frames/out-%03d.jpg&#34;</span></span></span></code></pre></div><p>Then I used IBM&rsquo;s cloud annotation tool to annotate the model.</p><p><img src=/img/grand_place/screenshot2.png alt=image></p><p>I was surprised on how much the model had improved by providing some more specific training data. This is the result:</p><p><img src=/img/grand_place/screenshot.jpg alt=image></p><p>The live result can be found <a href=https://grand-place.surge.sh>here</a>.</p></div></div></section><section class=section><div class="container has-text-centered"><p></p></div></section></body></html>